# UDACITY Data Engineering Nanodegree
## Introduction
Where we assumed the role of a Data Engineer at a fabricated data streaming company called “Sparkify” as it scales its data engineering in both size and sophistication. we worked with simulated data of listening behavior, as well as a wealth of metadata related to songs and artists. we started working with a small amount of data, with low complexity, processed and stored on a single machine. By the end, we developed a sophisticated set of data pipelines to work with massive amounts of data processed and stored on the cloud. There are some tasks and five projects in the program. Below is a description of each.

## Module 1 : Data Modeling
<<<<<<< HEAD
=======
>>>>>>> a1ecb3e734a9bc979c998403a147e6eaeef482a2

![Data Modeling](./1.Module01-DataModeling/images/Data_Model.png)

<hr/>

### Tasks:

1. Lesson 2 Demo 1: Creating Normalized Tables
[Click here to see the notebook](./1.Module01-DataModeling/1.1.Lesson2Demo1CreatingNormalizedTables/)
2. Lsson 2 Demo 2: Creating Denormalized Tables
[Click here to see the notebook](./1.Module01-DataModeling/1.2.Lsson2Demo2CreatingDenormalizedTables/)
3. Lesson 2 Demo 3: Creating Factand Dimension Tables with Star Schema
[Click here to see the notebook](./1.Module01-DataModeling/1.3.Lesson2Demo3CreatingFactandDimensionTableswithStarSchema/)
4. Exercise 2: Creating a Table with Apache Cassandra
[Click here to see the notebook](./1.Module01-DataModeling/1.4.Exercise2CreatingaTablewithApacheCassandra/)
5. Exercise 2: Primary Key
[Click here to see the notebook](./1.Module01-DataModeling/1.5.Exercise2PrimaryKey/)
6. Exercise 3: Clustering Column
[Click here to see the notebook](./1.Module01-DataModeling/1.6.Exercise3ClusteringColumn/)
7. Exercise 4: Using the WHERE Clause
[Click here to see the notebook](./1.Module01-DataModeling/1.7.Exercise4UsingtheWHEREClause/)

### Projects:
1. [Data Modeling with Postgres](./1.Module01-DataModeling/Project_Data_Modeling_with_Postgres/)
| Analyzing the songs of Sparkify by applying data modelling with Postgres and building an ETL pipeline using Python.
2. [Project_Data_Modeling_with_Apache_Cassandra](./1.Module01-DataModeling/Project_Data_Modeling_with_Apache_Cassandra/)
| Analyzing the songs of Sparkify by applying data modelling with Apache Cassandra and building an ETL pipeline that transfers data from a set of CSV files within a directory to create a streamlined CSV file to model and insert data into Apache Cassandra tables.
